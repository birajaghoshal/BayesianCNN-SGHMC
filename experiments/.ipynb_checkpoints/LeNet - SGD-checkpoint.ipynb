{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from edward.models import Categorical, Normal, Empirical\n",
    "import edward as ed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the TensorFlow method to download and/or load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data2/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data2/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data2/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data2/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data2/\",reshape=False,one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task is to classify the handwritten MNIST digits into one of the classes {0,1,2,...,9} and give a measure of the uncertainty of our classification. \n",
    "* Our machine learning model will be a simple soft-max regression, and for this we first need to choose a likelihood function to quantify the probability of the observed data given a set of parameters (weights and biases in our case). \n",
    "\n",
    "* We will use a Categorical likelihood function (see Chapter 2, Machine Learning: a Probabilistic Perspective by Kevin Murphy for a detailed description of Categorical distribution, also called Multinoulli distribution.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next set up some placeholder variables in TensorFlow. \n",
    "* This follows the same procedure as you would for a standard neural network except that we use Edward to place priors on the weights and biases. \n",
    "* In the code below, we place a normal Gaussian prior on the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ed.set_seed(314159)\n",
    "N = 64   # number of images in a minibatch.\n",
    "D = 784   # number of features.\n",
    "K = 10    # number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 0.1\n",
    "conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6)))\n",
    "conv1_b = tf.Variable(tf.zeros(6))\n",
    "\n",
    "conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "conv2_b = tf.Variable(tf.zeros(16))\n",
    "\n",
    "\n",
    "fc1_W = tf.Variable(tf.truncated_normal(shape=(256, 120), mean = mu, stddev = sigma))\n",
    "fc1_b = tf.Variable(tf.zeros(120))\n",
    "\n",
    "fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "fc2_b  = tf.Variable(tf.zeros(84))\n",
    "\n",
    "fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "fc3_b  = tf.Variable(tf.zeros(10))\n",
    "\n",
    "def lenet_forward(x,conv1_W,conv2_W, fc1_W, fc2_W,\n",
    "          fc3_W,conv1_b , conv2_b, fc1_b, fc2_b, fc3_b ):\n",
    "        \n",
    "        conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "        \n",
    "        conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "        fc0   = tf.contrib.layers.flatten(conv2)\n",
    "        fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "        fc1    = tf.nn.relu(fc1)\n",
    "        fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "        fc2    = tf.nn.relu(fc2)\n",
    "        logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "        \n",
    "        return logits\n",
    "def lenet_forward2(x,conv1_W,conv2_W,conv1_b , conv2_b ):\n",
    "        \n",
    "        conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "        \n",
    "        conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "        fc0   = tf.contrib.layers.flatten(conv2)\n",
    "        return fc0\n",
    "        \n",
    "def lenet_forward3(x,fc1_W, fc2_W,\n",
    "          fc3_W, fc1_b, fc2_b, fc3_b ):\n",
    "        \n",
    "        fc1   = tf.matmul(x, fc1_W) + fc1_b\n",
    "        fc1    = tf.nn.relu(fc1)\n",
    "        fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "        fc2    = tf.nn.relu(fc2)\n",
    "        logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "        \n",
    "        return logits\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "logits = lenet_forward(x,conv1_W,conv2_W, fc1_W, fc2_W,\n",
    "          fc3_W,conv1_b , conv2_b, fc1_b, fc2_b, fc3_b)\n",
    "y_ph = tf.one_hot(y, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels= y_ph)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-3)\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_ph, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lenet_forward(x,conv1_W,conv2_W, fc1_W, fc2_W,\n",
    "#           fc3_W,conv1_b , conv2_b, fc1_b, fc2_b, fc3_b ):\n",
    "        \n",
    "#         conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "#         conv1 = tf.nn.softmax(conv1)\n",
    "#         conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "        \n",
    "#         conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "#         conv2 = tf.nn.softmax(conv2)\n",
    "#         conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "#         fc0   = tf.contrib.layers.flatten(conv2)\n",
    "#         fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "#         fc1    = tf.nn.softmax(fc1)\n",
    "#         fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "#         fc2    = tf.nn.softmax(fc2)\n",
    "#         logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "        \n",
    "#         return logits\n",
    "# x = tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
    "\n",
    "# y = Categorical(lenet_forward(x,conv1_W,conv2_W, fc1_W, fc2_W,\n",
    "#           fc3_W,conv1_b , conv2_b, fc1_b, fc2_b, fc3_b))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "# Initalize all the variables in the session\n",
    "# tf.global_variables_initializer().run()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.203125\n",
      "0.15625\n",
      "0.203125\n",
      "0.28125\n",
      "0.40625\n",
      "0.390625\n",
      "0.421875\n",
      "0.5\n",
      "0.484375\n",
      "0.5\n",
      "0.484375\n",
      "0.609375\n",
      "0.640625\n",
      "0.640625\n",
      "0.59375\n",
      "0.609375\n",
      "0.640625\n",
      "0.734375\n",
      "0.765625\n",
      "0.78125\n",
      "0.734375\n",
      "0.796875\n",
      "0.78125\n",
      "0.765625\n",
      "0.6875\n",
      "0.796875\n",
      "0.71875\n",
      "0.828125\n",
      "0.84375\n",
      "0.78125\n",
      "0.765625\n",
      "0.828125\n",
      "0.8125\n",
      "0.875\n",
      "0.828125\n",
      "0.921875\n",
      "0.8125\n",
      "0.859375\n",
      "0.875\n",
      "0.890625\n",
      "0.796875\n",
      "0.828125\n",
      "0.765625\n",
      "0.859375\n",
      "0.828125\n",
      "0.828125\n",
      "0.84375\n",
      "0.875\n",
      "0.828125\n",
      "0.828125\n",
      "0.859375\n",
      "0.890625\n",
      "0.921875\n",
      "0.859375\n",
      "0.84375\n",
      "0.921875\n",
      "0.859375\n",
      "0.84375\n",
      "0.859375\n",
      "0.8125\n",
      "0.8125\n",
      "0.953125\n",
      "0.859375\n",
      "0.875\n",
      "0.921875\n",
      "0.84375\n",
      "0.8125\n",
      "0.875\n",
      "0.890625\n",
      "0.875\n",
      "0.90625\n",
      "0.890625\n",
      "0.96875\n",
      "0.953125\n",
      "0.921875\n",
      "0.921875\n",
      "0.90625\n",
      "0.84375\n",
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "#100 epochs\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "for i in range(625000):\n",
    "    X_batch, Y_batch = mnist.train.next_batch(64)\n",
    "    # Tensorflow method, gives the label data in a one hot vector format.\n",
    "    # We convert taht into a single label\n",
    "#     Y_batch = np.argmax(Y_batch, axis=1)\n",
    "    if i%10000==0:\n",
    "        res = sess.run(training_operation,feed_dict={x: X_batch, y_ph: Y_batch})\n",
    "        print(accuracy_operation.eval(feed_dict={x: X_batch, y_ph: Y_batch}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros_5:0\", shape=(5, 5), dtype=float32) (5, 5, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "a = conv1_W.eval()\n",
    "b = conv1_b.eval()\n",
    "c = conv2_W.eval()\n",
    "d = conv2_b.eval()\n",
    "print tf.zeros([5,5]), a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 256)\n"
     ]
    }
   ],
   "source": [
    "X_batch, Y_batch = mnist.train.next_batch(200)\n",
    "print lenet_forward2(X_batch,conv1_W,conv2_W,conv1_b , conv2_b ).eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define LeNet weights\n",
    "# mu = 0\n",
    "# sigma = 0.1\n",
    "# # conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "# # conv1_b = tf.Variable(tf.zeros(6))\n",
    "# conv1_W = Normal(loc=a, scale = tf.ones([5, 5, 1, 6]))\n",
    "# conv1_b= Normal(loc=b, scale = tf.ones(6))\n",
    "\n",
    "# conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "# conv2_b = tf.Variable(tf.zeros(16))\n",
    "\n",
    "# conv2_W = Normal(loc=c, scale = tf.ones([5, 5, 6, 16]))\n",
    "# conv2_b= Normal(loc=d, scale = tf.ones(16))\n",
    "\n",
    "# fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "# fc1_b = tf.Variable(tf.zeros(120))\n",
    "\n",
    "x2 = tf.placeholder(tf.float32,[None,256])\n",
    "fc1_W = Normal(loc=tf.zeros([256, 120]), scale = tf.ones([256, 120]))\n",
    "fc1_b= Normal(loc=tf.zeros(120), scale = tf.ones(120))\n",
    "\n",
    "# fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "# fc2_b  = tf.Variable(tf.zeros(84))\n",
    "\n",
    "fc2_W = Normal(loc=tf.zeros([120, 84]), scale = tf.ones([120, 84]))\n",
    "fc2_b= Normal(loc=tf.zeros(84), scale = tf.ones(84))\n",
    "\n",
    "# fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "# fc3_b  = tf.Variable(tf.zeros(10))\n",
    "\n",
    "fc3_W = Normal(loc=tf.zeros([84, 10]), scale = tf.ones([84, 10]))\n",
    "fc3_b= Normal(loc=tf.zeros(10), scale = tf.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y2 = Categorical(lenet_forward3(x2,fc1_W, fc2_W,\n",
    "          fc3_W, fc1_b, fc2_b, fc3_b ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qw = Normal(loc=tf.Variable(tf.random_normal([D,100])),\n",
    "#                            scale = tf.nn.softmax(tf.Variable(tf.random_normal([D,100]))))# dim of weights\n",
    "# qb = Normal(loc=tf.Variable(tf.random_normal([100])),\n",
    "#            scale = tf.nn.softmax(tf.Variable(tf.random_normal([100]))))\n",
    "\n",
    "# qw1 = Normal(loc=tf.Variable(tf.random_normal([100,K])),\n",
    "#                            scale = tf.nn.softmax(tf.Variable(tf.random_normal([100,K]))))# dim of weights\n",
    "# qb1 = Normal(loc=tf.Variable(tf.random_normal([K])),\n",
    "#            scale = tf.nn.softmax(tf.Variable(tf.random_normal([K]))))\n",
    "'''\n",
    "FOR KL DIVERGENCE\n",
    "'''\n",
    "# qconv1_W = Normal(loc=tf.Variable(tf.random_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma)),\n",
    "#                   scale = tf.Variable(tf.random_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma)))\n",
    "\n",
    "# qconv1_b = Normal(loc=tf.Variable(tf.random_normal([6])),\n",
    "#                   scale = tf.Variable(tf.random_normal([6])))\n",
    "                  \n",
    "\n",
    "# qconv2_W = Normal(loc=tf.Variable(tf.random_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma)),\n",
    "#                                  scale =tf.Variable(tf.random_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma) ))\n",
    "# qconv2_b = Normal(loc=tf.Variable(tf.random_normal([16])),\n",
    "#                   scale = tf.Variable(tf.random_normal([16])))\n",
    "\n",
    "\n",
    "# qfc1_W = Normal(loc=tf.Variable(tf.random_normal(shape=(256, 120), mean = mu, stddev = sigma)), \n",
    "#                 scale = tf.Variable(tf.random_normal(shape=(256, 120), mean = mu, stddev = sigma)))\n",
    "            \n",
    "# qfc1_b = Normal(loc=tf.Variable(tf.random_normal([120])),\n",
    "#                 scale = tf.Variable(tf.random_normal([120])))\n",
    "\n",
    "\n",
    "# qfc2_W  = Normal(loc=tf.Variable(tf.random_normal(shape=(120, 84), mean = mu, stddev = sigma)),\n",
    "#                  scale=tf.Variable(tf.random_normal(shape=(120, 84), mean = mu, stddev = sigma)))\n",
    "                                  \n",
    "# qfc2_b  =  Normal(loc=tf.Variable(tf.random_normal([84])),\n",
    "#                   scale = tf.Variable(tf.random_normal([84])))\n",
    "\n",
    "\n",
    "\n",
    "# qfc3_W  = Normal(loc=tf.Variable(tf.random_normal(shape=(84, 10), mean = mu, stddev = sigma)),\n",
    "#                  scale = tf.Variable(tf.random_normal(shape=(84, 10), mean = mu, stddev = sigma)))\n",
    "# qfc3_b  = Normal(loc=tf.Variable(tf.random_normal([10])),\n",
    "#                  scale=tf.Variable(tf.random_normal([10])))\n",
    "# T = 25000 #30 epochs at 64 batch size\n",
    "# T= 78125 #100 epochs at 64 batch size\n",
    "T= 62500 #800 epochs at 64 batch size\n",
    "\n",
    "qconv1_W = Empirical(params=tf.Variable(tf.zeros([T,5, 5, 1, 6])))\n",
    "\n",
    "qconv1_b = Empirical(params=tf.Variable(tf.zeros([T,6])))\n",
    "                  \n",
    "\n",
    "qconv2_W = Empirical(params=tf.Variable(tf.zeros([T,5, 5, 6, 16])))\n",
    "qconv2_b = Empirical(params=tf.Variable(tf.zeros([T,16])))\n",
    "\n",
    "\n",
    "qfc1_W = Empirical(params=tf.Variable(tf.random_normal([T,256,120])))\n",
    "            \n",
    "qfc1_b = Empirical(params=tf.Variable(tf.random_normal([T,120])))\n",
    "\n",
    "\n",
    "qfc2_W  = Empirical(params=tf.Variable(tf.random_normal([T,120,84])))\n",
    "                                  \n",
    "qfc2_b  =  Empirical(params=tf.Variable(tf.random_normal([T,84])))\n",
    "\n",
    "\n",
    "\n",
    "qfc3_W  = Empirical(params=tf.Variable(tf.random_normal([T,84,10])))\n",
    "qfc3_b  = Empirical(params=tf.Variable(tf.random_normal([T,10])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create placeholder to hold the data (in minibatches) in a Tensorflow graph\n",
    "# x = tf.placeholder(tf.float32,shape=[None,D])\n",
    "# # y = tf.placeholder(shape=[None,K])\n",
    "# # Normal (0,1 priors for variables)\n",
    "# w = Normal(loc=tf.zeros([D,100]), scale = tf.ones([D,100]))\n",
    "# b = Normal(loc=tf.zeros(100), scale = tf.ones(100))\n",
    "\n",
    "# w2 = Normal(loc=tf.zeros([100,K]), scale = tf.ones([100,K]))\n",
    "# b2 = Normal(loc=tf.zeros(K), scale = tf.ones(K))\n",
    "\n",
    "# # h = tf.matmul(x,w)+b \n",
    "\n",
    "\n",
    "# def simple_nn(x,w,w1,b,b1):\n",
    "#     h = tf.nn.softmax(tf.matmul(x,w)+b)\n",
    "#     y = tf.nn.softmax(tf.matmul(h,w1)+b1)\n",
    "#     return y\n",
    "\n",
    "# # Categorical likelihood for classification\n",
    "# y = Categorical(simple_nn(x,w,w2,b,b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point we have defined the likelihood P(y|x,;ω)P(y|x,;ω) and the prior P(ω)P(ω), next we want to use Bayes rule to compute the posterior P(ω|y,x)P(ω|y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we immediately face a problem because in practice the probability of the outputs P(y)P(y) is computationally intractable to compute for large instances and so we don't attempt to calculate the posterior directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle this problem we will instead be using Variational Inference (VI). In Variational Inference we choose a family of parameterised distributions Q(ω;λ)Q(ω;λ) over parameters ωω to approximate the true posterior, and then optimize the parameters λλ so as to match the true posterior distribution as best as possible. The core idea is to minimise what is known as the Kullback-Leibler divergence between the true posterior P(ω|y,x)P(ω|y,x) and the approximating ditribution Q(ω;λ)Q(ω;λ), which can be thought of as a measure of the disimilarity between two probability distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory behind VI is beyond the scope of this blog, so more more information a quick introduction to VI can be found in Edward's documentation and a detailed one in Variational Inference: A Review for Statisticians by Blei et al.. Chapter 33 or MacKay's book is also a very good reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So next we use Edward to set up the approximating distributions Qw(ω)Qw(ω) for the weights and Qb(ω)Qb(ω) for the biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct the q(w) and q(b). in this case we assume Normal distributions.\n",
    "# qw = Normal(loc=tf.Variable(tf.random_normal([D,100])),\n",
    "#                            scale = tf.nn.softmax(tf.Variable(tf.random_normal([D,100]))))# dim of weights\n",
    "# qb = Normal(loc=tf.Variable(tf.random_normal([100])),\n",
    "#            scale = tf.nn.softmax(tf.Variable(tf.random_normal([100]))))\n",
    "\n",
    "# qw1 = Normal(loc=tf.Variable(tf.random_normal([100,K])),\n",
    "#                            scale = tf.nn.softmax(tf.Variable(tf.random_normal([100,K]))))# dim of weights\n",
    "# qb1 = Normal(loc=tf.Variable(tf.random_normal([K])),\n",
    "#            scale = tf.nn.softmax(tf.Variable(tf.random_normal([K]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a placeholder for the labels in anticipation of the training data\n",
    "conv1_W = tf.Variable(tf.constant(a), name=\"w\")\n",
    "conv1_b = tf.Variable(tf.constant(b),name=\"b\")\n",
    "\n",
    "conv2_W = tf.Variable(tf.constant(c),name=\"w2\")\n",
    "conv2_b = tf.Variable(tf.constant(d),name=\"b2\")\n",
    "\n",
    "x2 = tf.placeholder(tf.float32,[None,256],name=\"x\")\n",
    "\n",
    "\n",
    "y2 = Categorical(lenet_forward3(x2,fc1_W, fc2_W,\n",
    "          fc3_W, fc1_b, fc2_b, fc3_b ), name=\"y\")\n",
    "\n",
    "y_ph = tf.placeholder(tf.int32, [64])\n",
    "x_ph = tf.placeholder(tf.float32, [256])\n",
    "# Define the VI inference technique, ie. minimize the KL divergence between q and p\n",
    "inference = ed.SGHMC({\n",
    "fc1_W:qfc1_W,\n",
    "fc1_b:qfc1_b,\n",
    "fc2_W:qfc2_W,\n",
    "fc2_b:qfc2_b,\n",
    "fc3_W:qfc3_W,\n",
    "fc3_b:qfc3_b}, data={y2:y_ph})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We use a placeholder for the labels in anticipation of the training data\n",
    "# y_ph = tf.placeholder(tf.int32, [N])\n",
    "# # Define the VI inference technique, ie. minimize the KL divergence between q and p\n",
    "# inference = ed.SGHMC({w: qw_1, b: qb_1}, data={y:y_ph})\n",
    "# inference.run(step_size=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.initialize(n_iter=5000, n_print=100, scale={y: float(mnist.train.num_examples) / N})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR KL'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Initalize the inference variables\n",
    "# Q: what does this do?!\n",
    "'''FOR SGHMC'''\n",
    "inference.initialize(n_iter=5000, n_print=100,step_size=1e-5,  scale={y: float(mnist.train.num_examples) / N})\n",
    "'''FOR KL'''\n",
    "# inference.initialize(n_iter=1000, n_print=100, scale={y: float(mnist.train.num_examples) / N})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we are ready to perform Variational Inference. \n",
    " We load up a TensorFlow session and start the iterations. Will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### tf.reset_default_graph()\n",
    "# We will use an interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "# Initalize all the variables in the session\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.beep = () => {\n",
       "    var snd = new Audio(\"data:audio/wav;base64,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\");  \n",
       "    snd.play();\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.beep = () => {\n",
    "    var snd = new Audio(\"data:audio/wav;base64,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\");  \n",
    "    snd.play();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.beep();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.beep();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = mnist.train.images\n",
    "# Tensorflow method gives the label data in a hot vector format. WE convert to single label.\n",
    "Y_tr = np.argmax(mnist.train.labels,axis=1)\n",
    "X_2_tr=lenet_forward2(X_tr,conv1_W,conv2_W,conv1_b , conv2_b ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.10508132,  3.67345548,  2.75372624, ...,  1.74510252,\n",
       "          0.8979007 ,  0.        ],\n",
       "        [ 1.71969104,  2.26408386,  3.11355591, ...,  0.68112165,\n",
       "          2.09776735,  0.27883694],\n",
       "        [ 0.08049539,  1.84489429,  1.62655926, ...,  3.15163779,\n",
       "          5.73815584,  0.0895058 ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.38587207,  0.032625  , ...,  0.56824547,\n",
       "          0.29161793,  0.        ],\n",
       "        [ 0.        ,  5.22600794,  1.05888414, ...,  1.82703817,\n",
       "          2.82192159,  0.        ],\n",
       "        [ 0.        ,  5.60109234,  2.82311654, ...,  3.00007844,\n",
       "          3.75580788,  0.        ]], dtype=float32),\n",
       " array([8, 4, 2, 6, 8, 0, 8, 3, 2, 4, 0, 3, 9, 2, 0, 4, 0, 7, 3, 9, 8, 2, 2,\n",
       "        6, 6, 3, 0, 9, 4, 2, 0, 7, 2, 5, 9, 7, 1, 4, 2, 6, 0, 0, 7, 5, 2, 5,\n",
       "        9, 5, 7, 9, 9, 9, 3, 3, 9, 1, 7, 2, 4, 9, 0, 6, 7, 9, 9, 1, 3, 3, 3,\n",
       "        4, 7, 8, 4, 9, 0, 9, 1, 1, 4, 3, 1, 8, 7, 0, 1, 3, 2, 2, 2, 7, 4, 2,\n",
       "        2, 2, 2, 1, 8, 1, 9, 5]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_batch(100,X_2_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 256)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_tr.shape\n",
    "#X_2_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.beep();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.beep();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78100/78125 [ 99%] █████████████████████████████  ETA: 0s | Acceptance Rate: 1.000"
     ]
    }
   ],
   "source": [
    "# Train model. \n",
    "# We load data in minibatches and update the VI inference using each new batch\n",
    "for _ in range(inference.n_iter):\n",
    "    X_batch_tr, Y_batch_tr = next_batch(64,X_2_tr,Y_tr)\n",
    "#     print type(X_batch)\n",
    "#     x2_batch = lenet_forward2(X_batch,conv1_W,conv2_W,conv1_b , conv2_b ).eval()\n",
    "    # Tensorflow method, gives the label data in a one hot vector format.\n",
    "    # We convert taht into a single label\n",
    "#     Y_batch = np.argmax(Y_batch_tr, axis=1)\n",
    "    info_dict = inference.update(feed_dict={x2: X_batch_tr, y_ph: Y_batch_tr})\n",
    "    inference.print_progress(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.beep();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.beep();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything that we need to run our model on the test data, let's see how good our model is! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major difference in Bayesian model evaluation is that there is no single value for the weights and biases that we should use to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Instead we should use the distribution of weights and biases in our model so that the uncertainties in these parameters are reflected in the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus instead of a single prediction we get a set of predictions and their accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw a 100 samples from the posterior distribution and see how we perform on each of these samples. Taking samples be might a slow process, may take few seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images\n",
    "X_test = mnist.test.images\n",
    "# Tensorflow method gives the label data in a hot vector format. WE convert to single label.\n",
    "Y_test = np.argmax(mnist.test.labels,axis=1)\n",
    "X_2_test=lenet_forward2(X_test,conv1_W,conv2_W,conv1_b , conv2_b ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "# Generate samples the posterior and store them\n",
    "n_samples = 100\n",
    "prob_lst = []\n",
    "samples = []\n",
    "conv1_W_samples = []\n",
    "conv1_b_samples = []\n",
    "conv2_W_samples = []\n",
    "conv2_b_samples = []\n",
    "fc1_W_samples = []\n",
    "fc1_b_samples = []\n",
    "fc2_W_samples = []\n",
    "fc2_b_samples = []\n",
    "fc3_W_samples = []\n",
    "fc3_b_samples = []\n",
    "for i in range(100):\n",
    "    print i\n",
    "    \n",
    "#     conv1_W_samp = qconv1_W.sample()\n",
    "#     conv1_b_samp=qconv1_b.sample()\n",
    "#     conv2_W_samp = qconv2_W.sample()\n",
    "#     conv2_b_samp = qconv2_b.sample()\n",
    "    fc1_W_samp = qfc1_W.sample()\n",
    "    fc1_b_samp = qfc1_b.sample()\n",
    "    fc2_W_samp= qfc2_W.sample()\n",
    "    fc2_b_samp = qfc2_b.sample()\n",
    "    fc3_W_samp = qfc3_W.sample()\n",
    "    fc3_b_samp = qfc3_b.sample()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     conv1_W_samples.append(conv1_W_samp)\n",
    "#     conv1_b_samples.append(conv1_b_samp)\n",
    "#     conv2_W_samples.append(conv2_W_samp)\n",
    "#     conv2_b_samples.append(conv2_b_samp)\n",
    "    fc1_W_samples.append(fc1_W_samp)\n",
    "    fc1_b_samples.append(fc1_b_samp)\n",
    "    fc2_W_samples.append(fc2_W_samp)\n",
    "    fc2_b_samples.append(fc2_b_samp)\n",
    "    fc3_W_samples.append(fc3_W_samp)\n",
    "    fc3_b_samples.append(fc3_b_samp)\n",
    "    # Also compute the probability of each class for each (w,b) sample.\n",
    "#     h = tf.nn.softmax(tf.matmul(X_test,w_samp) + b_samp)\n",
    "    prob= lenet_forward3(X_2_test,fc1_W_samp, fc2_W_samp,\n",
    "          fc3_W_samp, fc1_b_samp, fc2_b_samp, fc3_b_samp )\n",
    "#     print prob\n",
    "    \n",
    "    prob_lst.append(prob.eval())\n",
    "#     w_samp_reshape = tf.reshape(w_samp,[-1])\n",
    "#     sample = tf.concat([w_samp_reshape,b_samp],0)\n",
    "#     samples.append(sample.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model.\n",
    "\n",
    "accy_test = []\n",
    "for prob in prob_lst:\n",
    "    # For each sample we compute the predicted class and compare with the test labels\n",
    "    y_trn_prd = np.argmax(prob, axis=1).astype(np.float32)\n",
    "    # Predicted class is defined as the one which has maximum probability\n",
    "    # We preform this test for each (w,b) in the posterior giving us a set of accuracies\n",
    "    acc = (y_trn_prd == Y_test).mean()*100\n",
    "    accy_test.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x33aa56e90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEZCAYAAABxbJkKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2506f2350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally we make a histogram of accuracies for the test data.\n",
    "plt.hist(accy_test)\n",
    "plt.title(\"Histogram of prediction accuracies in the MNIST test data\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy in predicting the test data = ', 90.88000000000001)\n"
     ]
    }
   ],
   "source": [
    "# Here we compute the mean of probabilties for each class for all the (w,b) samples.\n",
    "# We then use the class with maximum of the mean proabilities as the prediction. \n",
    "# In other words, we have used (w,b) samples to construct a set of models and\n",
    "# used their combined outputs to make the predcitions.\n",
    "Y_pred = np.argmax(np.mean(prob_lst,axis=0),axis=1)\n",
    "print(\"accuracy in predicting the test data = \", (Y_pred == Y_test).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.beep();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.beep();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-7a1d74db8158>:1: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    }
   ],
   "source": [
    "v = tf.all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.train.save([x for x in v[:-6]])\n",
    "saver = tf.train.Saver([x for x in v[:-6]], \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n\nCaused by op u'save_3/RestoreV2', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Library/Python/2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Python/2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Python/2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Python/2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Python/2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-852cefd24b87>\", line 2, in <module>\n    saver = tf.train.Saver([x for x in v[:-6]], \"model.ckpt\")\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a396b04e17c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Restore variables from disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Check the values of the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n\nCaused by op u'save_3/RestoreV2', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Library/Python/2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Python/2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Python/2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Python/2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Python/2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Python/2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Python/2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-852cefd24b87>\", line 2, in <module>\n    saver = tf.train.Saver([x for x in v[:-6]], \"model.ckpt\")\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_3/Const_0_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc1_W = tf.Variable(tf.truncated_normal(shape=(256, 120), mean = mu, stddev = sigma))\n",
    "# fc1_b = tf.Variable(tf.zeros(120))\n",
    "\n",
    "# fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "# fc2_b  = tf.Variable(tf.zeros(84))\n",
    "\n",
    "# fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "# fc3_b  = tf.Variable(tf.zeros(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
